{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRR8oZ5dtY0Q"
      },
      "source": [
        "# EJERCICIO DE ANALISIS DE SENTIMIENTOS USANDO EMBEDDINGS PREENTRENADOS Y REDES NEURONALES CON TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "jCu-BXZ_ssgk",
        "outputId": "afc0ba52-e8ea-4173-c793-2b3b11344581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ac0adffac5564fb49dfe294e630eed6a",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install numpy==1.26.4 scipy==1.13.1 gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nae48ZAUuJQX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RbQX5DZuMs_"
      },
      "source": [
        "# creamos dataset de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sXOSITu9uPFK"
      },
      "outputs": [],
      "source": [
        "#  Simulaci贸n de carga de un dataset (puedes reemplazar por un CSV real)\n",
        "tweets = [\n",
        "    'Este producto es una maravilla',\n",
        "    'No recomiendo comprar esto',\n",
        "    'Excelente atenci贸n y calidad',\n",
        "    'Muy mala experiencia, p茅simo servicio',\n",
        "    'Totalmente satisfecho con mi compra',\n",
        "    'No funciona como esperaba',\n",
        "    'Una compra perfecta y r谩pida',\n",
        "    'Decepcionante, esperaba algo mejor'\n",
        "]\n",
        "\n",
        "# 1 = positivo, 0 = negativo\n",
        "labels = [1, 0, 1, 0, 1, 0, 1, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C4iQ-LLuR5f"
      },
      "source": [
        "# TOKENIZACION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DrGhagVuTVo",
        "outputId": "d57908db-67db-4b14-b959-f51dba3fa25b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'una': 1,\n",
              " 'no': 2,\n",
              " 'y': 3,\n",
              " 'compra': 4,\n",
              " 'esperaba': 5,\n",
              " 'este': 6,\n",
              " 'producto': 7,\n",
              " 'es': 8,\n",
              " 'maravilla': 9,\n",
              " 'recomiendo': 10,\n",
              " 'comprar': 11,\n",
              " 'esto': 12,\n",
              " 'excelente': 13,\n",
              " 'atenci贸n': 14,\n",
              " 'calidad': 15,\n",
              " 'muy': 16,\n",
              " 'mala': 17,\n",
              " 'experiencia': 18,\n",
              " 'p茅simo': 19,\n",
              " 'servicio': 20,\n",
              " 'totalmente': 21,\n",
              " 'satisfecho': 22,\n",
              " 'con': 23,\n",
              " 'mi': 24,\n",
              " 'funciona': 25,\n",
              " 'como': 26,\n",
              " 'perfecta': 27,\n",
              " 'r谩pida': 28,\n",
              " 'decepcionante': 29,\n",
              " 'algo': 30,\n",
              " 'mejor': 31}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Tokenizaci贸n\n",
        "tokenizer = Tokenizer()\n",
        "# Fit tokenizer on lowercased tweets to align with Word2Vec vocabulary\n",
        "tweets_tokenized = [tweet.lower().split() for tweet in tweets]\n",
        "tokenizer.fit_on_texts([' '.join(tweet) for tweet in tweets_tokenized])\n",
        "sequences = tokenizer.texts_to_sequences([' '.join(tweet) for tweet in tweets_tokenized])\n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WrwXBmR_uhAa"
      },
      "outputs": [],
      "source": [
        "padded_sequences = pad_sequences(sequences, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiMCT-kxukAw"
      },
      "source": [
        "# ENTRENAR LOS TWEETS TOKENIZADOS CON WORD2VEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q_9ukhZJuodX"
      },
      "outputs": [],
      "source": [
        "w2v_model = Word2Vec(tweets_tokenized, vector_size=100, window=3, min_count=1, sg=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQjxjyenuv7Q"
      },
      "source": [
        "# CREO UNA MATRIZ DE EMBEDDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mslKgtWduzh4"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(word_index) + 1\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    # Check if the word is in the Word2Vec model's vocabulary before accessing\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_vector = w2v_model.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTmgKLtCu_u6",
        "outputId": "917161ac-39d3-43a1-e8eb-a38c88871877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [-5.36209613e-04,  2.33797240e-04,  5.10245934e-03, ...,\n",
              "        -7.04496354e-03,  9.00856685e-04,  6.39314251e-03],\n",
              "       [ 9.45639622e-05,  3.07731982e-03, -6.81264512e-03, ...,\n",
              "         5.12590399e-04,  8.21308419e-03, -7.01904064e-03],\n",
              "       ...,\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
              "       [ 9.73111484e-03, -9.79223382e-03, -6.50790054e-03, ...,\n",
              "        -2.72329105e-03,  3.82445473e-03,  3.32233176e-04],\n",
              "       [-8.71688314e-03,  2.10690335e-03, -8.84466222e-04, ...,\n",
              "        -8.71822610e-03,  2.95548537e-03, -6.67331927e-03]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0FtThpvEXg"
      },
      "source": [
        "# CREAR EL MODELO DE RED NEURONAL CON TENSORFLOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p00zSh9vHfY",
        "outputId": "a22c8a4c-4ca4-4b91-f04b-c946b6a7e49f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size,\n",
        "              output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix],\n",
        "              input_length=padded_sequences.shape[1],\n",
        "              trainable=False),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UipNS6Ckvc6Z"
      },
      "source": [
        "# COMPILAR EL MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NA4le1ITved6"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzjmN0uyvgbQ"
      },
      "source": [
        "# ENTRENAR EL MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r-yilFjviQZ",
        "outputId": "0fa73d20-36ce-49c4-9b9d-071b2f9c6b88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 2/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8750 - loss: 0.6922\n",
            "Epoch 3/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8750 - loss: 0.6915\n",
            "Epoch 4/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8750 - loss: 0.6911\n",
            "Epoch 5/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8750 - loss: 0.6907\n",
            "Epoch 6/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6903\n",
            "Epoch 7/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.6900\n",
            "Epoch 8/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.6898\n",
            "Epoch 9/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.6896\n",
            "Epoch 10/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.6893\n",
            "Epoch 11/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6891\n",
            "Epoch 12/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6889\n",
            "Epoch 13/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.6887\n",
            "Epoch 14/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6885\n",
            "Epoch 15/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6883\n",
            "Epoch 16/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.6881\n",
            "Epoch 17/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6878\n",
            "Epoch 18/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.6875\n",
            "Epoch 19/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.6873\n",
            "Epoch 20/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.6870\n",
            "Epoch 21/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.6868\n",
            "Epoch 22/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6865\n",
            "Epoch 23/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.6863\n",
            "Epoch 24/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.6860\n",
            "Epoch 25/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.6858\n",
            "Epoch 26/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.6855\n",
            "Epoch 27/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6853\n",
            "Epoch 28/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.6850\n",
            "Epoch 29/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6848\n",
            "Epoch 30/30\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.6845\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d2fc7597790>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(padded_sequences, np.array(labels), epochs=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRuQL2R2vlrw"
      },
      "source": [
        "# PROBAR EL MODELO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_dvSI8TvoGB",
        "outputId": "71f217e8-1348-4113-c4d1-7d7b5a9ba06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
            "Probabilidad de ser positivo: 0.49868544936180115\n",
            "Sentimiento: Negativo\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-11-1103175599.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  print('Probabilidad de ser positivo:', float(prediccion[0]))\n"
          ]
        }
      ],
      "source": [
        "#  Predicci贸n sobre un tweet nuevo\n",
        "tweet_nuevo = ['p茅simo producto, muy decepcionado']\n",
        "seq_nuevo = tokenizer.texts_to_sequences(tweet_nuevo)\n",
        "seq_nuevo_padded = pad_sequences(seq_nuevo, maxlen=padded_sequences.shape[1], padding='post')\n",
        "prediccion = model.predict(seq_nuevo_padded)\n",
        "\n",
        "print('Probabilidad de ser positivo:', float(prediccion[0]))\n",
        "print('Sentimiento:', 'Positivo' if prediccion[0] > 0.5 else 'Negativo')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
